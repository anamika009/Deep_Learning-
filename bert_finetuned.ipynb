{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df47b8",
   "metadata": {
    "id": "Y4fsZ38lZWil",
    "outputId": "603218ab-56f7-43bb-d3f7-66449ef19897",
    "papermill": {
     "duration": 0.015181,
     "end_time": "2024-04-01T16:18:06.098611",
     "exception": false,
     "start_time": "2024-04-01T16:18:06.083430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9599d685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T16:18:06.129307Z",
     "iopub.status.busy": "2024-04-01T16:18:06.128938Z",
     "iopub.status.idle": "2024-04-01T16:18:07.954210Z",
     "shell.execute_reply": "2024-04-01T16:18:07.953291Z"
    },
    "id": "t4XlssTYZhyJ",
    "outputId": "3bc0f969-05e0-4003-fc36-6c358e30d2f2",
    "papermill": {
     "duration": 1.84269,
     "end_time": "2024-04-01T16:18:07.956111",
     "exception": false,
     "start_time": "2024-04-01T16:18:06.113421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d3820d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T16:18:07.988012Z",
     "iopub.status.busy": "2024-04-01T16:18:07.987151Z",
     "iopub.status.idle": "2024-04-01T16:18:07.991329Z",
     "shell.execute_reply": "2024-04-01T16:18:07.990509Z"
    },
    "id": "UrRQtQt7Zmka",
    "papermill": {
     "duration": 0.021819,
     "end_time": "2024-04-01T16:18:07.993181",
     "exception": false,
     "start_time": "2024-04-01T16:18:07.971362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data_path = \"G:/PARAG_S/A1_part2/data/data/train.json\"\n",
    "test_data_path = \"G:/PARAG_S/A1_part2/data/data/test.json\"\n",
    "val_data_path = \"G:/PARAG_S/A1_part2/data/data/dev.json\"\n",
    "glove_path = \"G:/NLP_assignment_2/glove.6B.100d.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f007bc20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T16:18:08.024387Z",
     "iopub.status.busy": "2024-04-01T16:18:08.024111Z",
     "iopub.status.idle": "2024-04-01T16:19:21.284220Z",
     "shell.execute_reply": "2024-04-01T16:19:21.283297Z"
    },
    "id": "ysYHpK0xZrSL",
    "outputId": "0fcd0d4d-1f23-4199-c929-7e398b9c4eb1",
    "papermill": {
     "duration": 73.278434,
     "end_time": "2024-04-01T16:19:21.286426",
     "exception": false,
     "start_time": "2024-04-01T16:18:08.007992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "# nltk.download('punkt')\n",
    "# Load data from JSON file\n",
    "# Loading  training_data from JSON file\n",
    "with open(train_data_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "#loading validation_data from json file\n",
    "with open(val_data_path, 'r') as file:\n",
    "    val_data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "#loading test_data from json file\n",
    "with open(test_data_path, 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for problem_data in data:\n",
    "    problem = problem_data[\"Problem\"]\n",
    "    linear_formula = problem_data[\"linear_formula\"]\n",
    "    answer = problem_data[\"answer\"]\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prepare_data_for_bert(data, tokenizer, max_length=256):\n",
    "  \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for item in data:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            item,                      # Problem text to encode.\n",
    "            add_special_tokens=True,   # Add '[CLS]' and '[SEP]'.\n",
    "            max_length=max_length,     # Pad & truncate all texts.\n",
    "            padding='max_length',      # Pad all to max_length.\n",
    "            truncation=True,           # Truncate to max_length.\n",
    "            return_attention_mask=True,# Construct attention masks.\n",
    "            return_tensors='pt',       # Return pytorch tensors.\n",
    "       )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "problem_texts = [item[\"Problem\"].lower() for item in data]\n",
    "input_ids, attention_masks = prepare_data_for_bert(problem_texts, tokenizer)\n",
    "\n",
    "val_problem_texts = [item[\"Problem\"].lower() for item in val_data] \n",
    "val_input_ids, val_attention_masks = prepare_data_for_bert(val_problem_texts, tokenizer)\n",
    "\n",
    "test_problem_texts = [item[\"Problem\"].lower() for item in test_data] \n",
    "test_input_ids, test_attention_masks = prepare_data_for_bert(test_problem_texts, tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "for problem_data in data:\n",
    "    problem = problem_data[\"Problem\"]\n",
    "    linear_formula = problem_data[\"linear_formula\"]\n",
    "    answer = problem_data[\"answer\"]\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_formula(formula):\n",
    "    # Split the formula by '|'\n",
    "    parts = formula.split('|')\n",
    "\n",
    "    # Tokenize each part\n",
    "    tokens = ['<sos>']\n",
    "    for part in parts:\n",
    "        if part:  # check if part is not empty\n",
    "            \n",
    "            open_parenthesis_index = part.find('(')\n",
    "            if open_parenthesis_index != -1:\n",
    "                function = part[:open_parenthesis_index]\n",
    "                arguments = part[open_parenthesis_index+1:-1] \n",
    "                arguments_tokens = arguments.split(',')\n",
    "                # print(arguments_tokens)\n",
    "                arguments_token_new=[]\n",
    "                for tok in arguments_tokens:\n",
    "                    arguments_token_new.append(tok)\n",
    "                    arguments_token_new.append(',')\n",
    "                    \n",
    "                tokens.extend([function, '('] + arguments_token_new[:-1] + [')'])\n",
    "            else:\n",
    "                tokens.append(part)\n",
    "        if tokens[-1] != '|':\n",
    "            tokens.append('|')\n",
    "    tokens.append(\"<eos>\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def build_vocab(texts, is_formula=False):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        if is_formula:\n",
    "            tokens = tokenize_formula(text.lower())  \n",
    "        else:\n",
    "            tokens = word_tokenize(text.lower())  \n",
    "        counter.update(tokens)\n",
    "\n",
    "    # Start the vocab with special tokens\n",
    "    vocab = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\":3, \"<digit>\": 4}\n",
    "\n",
    "\n",
    " \n",
    "    for word in counter:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab, counter\n",
    "\n",
    "\n",
    "# Separate problem texts and linear formulas\n",
    "import numpy as np\n",
    "problem_texts = [item[\"Problem\"].lower() for item in data]\n",
    "linear_formulas = [item[\"linear_formula\"].lower() for item in data]\n",
    "\n",
    "# Build vocabularies\n",
    "problem_vocab, _ = build_vocab(problem_texts)\n",
    "formula_vocab, _ = build_vocab(linear_formulas, is_formula=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def text_to_indices(text, vocab):\n",
    "    tokens = word_tokenize(text.lower()) + ['<eos>']  \n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens if not token.isdigit()]\n",
    "\n",
    "\n",
    "# def text_to_indices(text, vocab):\n",
    "#     return [vocab.get(token, vocab[\"<unk>\"]) for token in word_tokenize(text.lower()) if not token.isdigit()]\n",
    "def text_to_indices_formula(text, vocab):\n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokenize_formula(text.lower())]\n",
    "# def text_to_indices(text, vocab):\n",
    "#     for token in word_tokenize(text.lower()):\n",
    "#         if not token.isdigit():\n",
    "#             return [vocab.get(token, vocab[\"<unk>\"])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokenized_problems = [text_to_indices(item[\"Problem\"], problem_vocab) for item in data]\n",
    "tokenized_formulas = [text_to_indices_formula(item[\"linear_formula\"], formula_vocab) for item in data]\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MathProblemDataset(Dataset):\n",
    "    def __init__(self, problems, attention_masks, formulas):\n",
    "        self.problems = problems\n",
    "        self.attention_masks = attention_masks\n",
    "        self.formulas = formulas\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.problems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        problem = self.problems[idx]\n",
    "        attention_mask = self.attention_masks[idx]\n",
    "        formula = torch.tensor(self.formulas[idx], dtype=torch.long)\n",
    "        return {\n",
    "            \"problem\": problem,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"formula\": formula\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "   \n",
    "    problems = [item[\"problem\"] for item in batch]\n",
    "    attention_masks = [item[\"attention_mask\"] for item in batch]\n",
    "    formulas = [item[\"formula\"] for item in batch]\n",
    "\n",
    "    \n",
    "    problems = torch.stack(problems)\n",
    "    attention_masks = torch.stack(attention_masks)\n",
    "\n",
    "   \n",
    "    formulas_padded = pad_sequence(formulas, batch_first=True, padding_value=formula_vocab[\"<pad>\"])\n",
    "\n",
    "    return {\n",
    "        \"problem\": problems,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"formula\": formulas_padded\n",
    "    }\n",
    "\n",
    "\n",
    "tokenized_problems = [text_to_indices(item[\"Problem\"], problem_vocab) for item in data]\n",
    "tokenized_formulas = [text_to_indices_formula(item[\"linear_formula\"], formula_vocab) for item in data]\n",
    "\n",
    "#tokenizing validation data\n",
    "\n",
    "tokenized_val_problems = [text_to_indices(item[\"Problem\"], problem_vocab) for item in val_data]\n",
    "tokenized_val_formulas = [text_to_indices_formula(item[\"linear_formula\"], formula_vocab) for item in val_data]\n",
    "\n",
    "\n",
    "#tokenizing test data\n",
    "tokenized_test_problems = [text_to_indices(item[\"Problem\"], problem_vocab) for item in test_data]\n",
    "tokenized_test_formulas = [text_to_indices_formula(item[\"linear_formula\"], formula_vocab) for item in test_data]\n",
    "\n",
    "\n",
    "dataset = MathProblemDataset(input_ids, attention_masks, tokenized_formulas)\n",
    "\n",
    "val_dataset = MathProblemDataset(val_input_ids, val_attention_masks, tokenized_val_formulas)\n",
    "\n",
    "test_dataset = MathProblemDataset(test_input_ids, test_attention_masks, tokenized_test_formulas)\n",
    "\n",
    "# Create DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=20 ,shuffle=True, collate_fn=collate_fn)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=20, shuffle=True, collate_fn=collate_fn)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=20, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# sample_batch = next(iter(data_loader))\n",
    "# sample_batch['formula']\n",
    "# formula_vocab\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # print(f'enc dim {enc_hid_dim} | dec dim {dec_hid_dim}')\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: [batch size, dec hid dim]\n",
    "\n",
    "\n",
    "        # print(f'initial hidden {hidden.shape}')\n",
    "        # print(f'encoder_output {encoder_outputs.shape}')\n",
    "        # encoder_outputs: [src len, batch size, enc hid dim * 2]\n",
    "        # encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # print(encoder_outputs.shape)\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        # print(src_len)\n",
    "\n",
    "        # repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "\n",
    "\n",
    "        # print(f'inside attention | hidden : {hidden.shape} | encoder_outputs : {encoder_outputs.shape}')\n",
    "        # print(f'concat {torch.cat((hidden, encoder_outputs), dim=2).shape}')\n",
    "\n",
    "        # Calculate energy\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        # print(f'energy {energy.shape}')\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        # print(f'attention {attention.shape}')\n",
    "\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "class BERT_Encoder(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-cased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "        # Freeze BERT parameters to prevent them from being updated during training\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.reduce_dim=nn.Linear(768,256)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # BERT returns a tuple, where the first element is the last hidden state\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        # last_hidden_state shape: [batch_size, sequence_length, hidden_size]\n",
    "        # For BERT-base-cased, hidden_size is 768\n",
    "        # print(f'inside encoder | outputs : {outputs} | last_hidden_state : {last_hidden_state}')\n",
    "        reduced_state=self.reduce_dim(last_hidden_state)\n",
    "        return reduced_state\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        # input = [batch size]\n",
    "        # hidden = [batch size, dec hid dim]\n",
    "        # cell = [batch size, dec hid dim]\n",
    "        # encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        input = input.unsqueeze(0)  # input = [1, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))  # embedded = [1, batch size, emb dim]\n",
    "\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)  # a = [batch size, 1, src len]\n",
    "\n",
    "        encoder_outputs = encoder_outputs  # encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        # print(f'encoder_outputs {encoder_outputs.shape}')\n",
    "        weighted = torch.bmm(a, encoder_outputs)  # weighted = [batch size, 1, enc hid dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)  # weighted = [1, batch size, enc hid dim * 2]\n",
    "\n",
    "        # Combine embedded input word and weighted context, and pass to LSTM\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden.unsqueeze(0), cell.unsqueeze(0)))\n",
    "\n",
    "       \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "\n",
    "        return prediction, hidden.squeeze(0), cell.squeeze(0), a.squeeze(1)\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device,  bert_output_dim=256, dec_hid_dim=256):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        \n",
    "        self.fc_hidden = nn.Linear(bert_output_dim,dec_hid_dim)\n",
    "        self.fc_cell = nn.Linear(bert_output_dim, dec_hid_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, trg, teacher_forcing_ratio=0.6):\n",
    "        # input_ids = [batch size, src len]\n",
    "        # trg = [batch size, trg len]\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len-1, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        \n",
    "        encoder_outputs = self.encoder(input_ids, attention_mask)\n",
    "\n",
    "        # Initialize hidden and cell states\n",
    "        hidden = torch.tanh(self.fc_hidden(encoder_outputs[:, 0]))\n",
    "        cell = torch.tanh(self.fc_cell(encoder_outputs[:, 0]))\n",
    "\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(0, trg_len-1):\n",
    "            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t+1] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    " # Embedding dimension for encoder\n",
    "DEC_EMB_DIM = 100  # Embedding dimension for decoder\n",
    "ENC_HID_DIM = 128  # Hidden dimension for encoder\n",
    "DEC_HID_DIM = 256  # Hidden dimension for decoder \n",
    "# ENC_DROPOUT = 0.5  # Dropout rate for encoder\n",
    "DEC_DROPOUT = 0.5  # Dropout rate for decoder\n",
    "OUTPUT_DIM = len(formula_vocab)\n",
    "\n",
    "encoder = BERT_Encoder().to(device)\n",
    "attention = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attention)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AdamW\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder_params = list(model.encoder.bert.named_parameters())\n",
    "other_params = [p for n, p in model.named_parameters() if not n.startswith('encoder.bert')]\n",
    "# Define the optimizer\n",
    "optimizer = AdamW([\n",
    "    {'params': [p for _, p in encoder_params], 'lr': 5e-5},  # Lower learning rate for BERT\n",
    "    {'params': other_params, 'lr': 1e-3}  # Higher learning rate for the rest of the model\n",
    "])\n",
    "\n",
    "\n",
    "PAD_IDX = formula_vocab[\"<pad>\"] \n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(device)\n",
    "\n",
    "\n",
    "# def train(model, iterator, optimizer, criterion, clip):\n",
    "#     model.train()  # Set the model to training mode\n",
    "#     epoch_loss = 0\n",
    "\n",
    "#     for i, batch in enumerate(tqdm(iterator)):\n",
    "#         input_ids = batch['problem'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         trg = batch['formula'].to(device)\n",
    "#         # print(f'target {trg}')\n",
    "\n",
    "#         # Adjust target tensor to fit expected output structure, shifting it by one to ignore <sos> token for loss calculation\n",
    "#         trg_input = trg\n",
    "#         trg_output = trg[:, 1:]\n",
    "#         # trg_new = trg[:, 1:]\n",
    "#         # print(f'trg_out : {trg_output.shape}')\n",
    "#         # print(f'trg_output : {trg_output}')\n",
    "\n",
    "#         optimizer.zero_grad()  # Clear any previously calculated gradients\n",
    "\n",
    "#         output = model(input_ids, attention_mask, trg_input)\n",
    "#         # print(f'output {output.shape}')\n",
    "\n",
    "#         # Reshape output and target tensors to compute loss\n",
    "#         output_dim = output.shape[-1]\n",
    "#         # output = output.contiguous().view(-1, output_dim)\n",
    "#         # trg_output = trg_output.contiguous().view(-1)\n",
    "#         output=output.permute(1,2,0)\n",
    "#         # Calculate loss\n",
    "#         loss = criterion(output, trg_output)\n",
    "#         loss.backward()  # Backpropagate the loss\n",
    "\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # Gradient clipping\n",
    "\n",
    "#         optimizer.step()  # Update model parameters\n",
    "\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, accumulation_steps):\n",
    "    model.train()  \n",
    "    epoch_loss = 0\n",
    "    optimizer.zero_grad()  \n",
    "\n",
    "    for i, batch in enumerate(tqdm(iterator)):\n",
    "        input_ids = batch['problem'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        trg = batch['formula'].to(device)\n",
    "\n",
    "      \n",
    "        trg_input = trg\n",
    "        trg_output = trg[:, 1:]\n",
    "\n",
    "        output = model(input_ids, attention_mask, trg_input)\n",
    "\n",
    "        # Reshaping output and target tensors to compute loss\n",
    "        output = output.permute(1, 2, 0)\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, trg_output)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        # Perform optimization step after accumulation_steps\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(iterator):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  # Clear gradients for next accumulation\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()  \n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(iterator):\n",
    "            input_ids = batch['problem'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            trg = batch['formula'].to(device)\n",
    "\n",
    "            #  shifting it by one to ignore <sos> token for loss calculation\n",
    "            trg_input = trg\n",
    "            trg_output = trg[:, 1:]\n",
    "\n",
    "            output = model(input_ids, attention_mask, trg_input)\n",
    "\n",
    "            \n",
    "            output = output.permute(1, 2, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, trg_output)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd3fc71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T16:19:21.321395Z",
     "iopub.status.busy": "2024-04-01T16:19:21.320632Z",
     "iopub.status.idle": "2024-04-02T01:03:08.371210Z",
     "shell.execute_reply": "2024-04-02T01:03:08.370368Z"
    },
    "id": "QE26t4BvZuy9",
    "outputId": "3c7fe387-e36d-43b2-f765-426a281d2078",
    "papermill": {
     "duration": 31427.070504,
     "end_time": "2024-04-02T01:03:08.373596",
     "exception": false,
     "start_time": "2024-04-01T16:19:21.303092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:56<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.0883, Val Loss: 0.7559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 0.7105, Val Loss: 0.6539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 0.6028, Val Loss: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:56<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 0.5232, Val Loss: 0.5180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:56<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 0.4623, Val Loss: 0.4965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:59<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Loss: 0.4107, Val Loss: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:59<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Loss: 0.3716, Val Loss: 0.4660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train Loss: 0.3397, Val Loss: 0.4216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Loss: 0.3088, Val Loss: 0.4230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 0.2826, Val Loss: 0.4175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:56<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Loss: 0.2606, Val Loss: 0.4038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Loss: 0.2436, Val Loss: 0.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Loss: 0.2290, Val Loss: 0.3961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:56<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Loss: 0.2134, Val Loss: 0.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Loss: 0.2006, Val Loss: 0.3880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Loss: 0.1870, Val Loss: 0.3921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train Loss: 0.1755, Val Loss: 0.3969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train Loss: 0.1662, Val Loss: 0.3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train Loss: 0.1579, Val Loss: 0.3881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train Loss: 0.1489, Val Loss: 0.3928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:56<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train Loss: 0.1423, Val Loss: 0.4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train Loss: 0.1354, Val Loss: 0.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train Loss: 0.1302, Val Loss: 0.4097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train Loss: 0.1235, Val Loss: 0.4073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train Loss: 0.1172, Val Loss: 0.4109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train Loss: 0.1141, Val Loss: 0.4298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train Loss: 0.1062, Val Loss: 0.4272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:59<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train Loss: 0.1041, Val Loss: 0.4158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:59<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train Loss: 0.0973, Val Loss: 0.4152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train Loss: 0.0940, Val Loss: 0.4194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train Loss: 0.0893, Val Loss: 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train Loss: 0.0869, Val Loss: 0.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train Loss: 0.0850, Val Loss: 0.4281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train Loss: 0.0800, Val Loss: 0.4346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train Loss: 0.0779, Val Loss: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train Loss: 0.0764, Val Loss: 0.4668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:56<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train Loss: 0.0737, Val Loss: 0.4455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train Loss: 0.0684, Val Loss: 0.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train Loss: 0.0666, Val Loss: 0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train Loss: 0.0656, Val Loss: 0.4709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train Loss: 0.0623, Val Loss: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train Loss: 0.0617, Val Loss: 0.4652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train Loss: 0.0595, Val Loss: 0.5122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train Loss: 0.0577, Val Loss: 0.5091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train Loss: 0.0550, Val Loss: 0.4783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:58<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train Loss: 0.0558, Val Loss: 0.4914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train Loss: 0.0530, Val Loss: 0.4977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:57<00:00,  1.66it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train Loss: 0.0509, Val Loss: 0.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:59<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:30<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train Loss: 0.0509, Val Loss: 0.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [09:59<00:00,  1.65it/s]\n",
      "100%|██████████| 149/149 [00:29<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train Loss: 0.0483, Val Loss: 0.5163\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, train_losses, val_losses, epoch, checkpoint_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "\n",
    "clip = 1  # Gradient clipping value\n",
    "num_epochs = 50  # Number of epochs to train\n",
    "best_val_loss = float('inf')\n",
    "checkpoint_path = '/kaggle/working//model_BERT_checkpoint.pt'\n",
    "\n",
    "\n",
    "clip = 1  # Gradient clipping value\n",
    "num_epochs = 50  # Number of epochs to train\n",
    "accumulation_steps = 4  # Number of steps to accumulate gradients before performing optimization\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, data_loader, optimizer, criterion, clip, accumulation_steps)\n",
    "    val_loss = evaluate(model, val_data_loader, criterion)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(model, optimizer, train_losses, val_losses, epoch, checkpoint_path)\n",
    "\n",
    "torch.save(model.state_dict(), '/kaggle/working/01_04_BERT_finetuned.pt')\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train(model, data_loader, optimizer, criterion, clip)\n",
    "#     val_loss = evaluate(model, val_data_loader, criterion)\n",
    "#     print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "#     train_losses.append(train_loss)\n",
    "#     val_losses.append(val_loss)\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         save_checkpoint(model, optimizer, train_losses, val_losses, epoch, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a2df45",
   "metadata": {
    "id": "LkuyqPKcOD2-",
    "outputId": "8040efb5-7c70-4e22-be13-8491299f20e0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): BERT_Encoder(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (reduce_dim): Linear(in_features=768, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(145, 100)\n",
       "    (rnn): LSTM(356, 256)\n",
       "    (fc_out): Linear(in_features=612, out_features=145, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc_hidden): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc_cell): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_path = \"G:/final_part_2/lstm-bert-tuned/01_04_BERT_finetuned.pt\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the model state dict\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()  # or model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7afad",
   "metadata": {
    "id": "9cnZV85-2bXD",
    "outputId": "1dd0f525-8110-4210-fb6f-052a9c88e941",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hidden, previousNode, wordId, logProb, length):\n",
    "        self.hidden = hidden\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.length = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        \n",
    "        return self.logp / float(self.length - 1 + 1e-6) + alpha * reward\n",
    "\n",
    "def beam_search(model, input_ids, attention_mask, beam_width=10, max_len=50):\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.encoder(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        hidden = torch.tanh(model.fc_hidden(encoder_outputs[:, 0]))\n",
    "        cell = torch.tanh(model.fc_cell(encoder_outputs[:, 0]))\n",
    "\n",
    "    start_node = BeamSearchNode((hidden, cell), None, formula_vocab[\"<sos>\"], 0, 1)\n",
    "    nodes = [start_node]\n",
    "\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        new_nodes = []\n",
    "        for node in nodes:\n",
    "            input = torch.LongTensor([node.wordid]).to(device)\n",
    "            hidden, cell = node.hidden\n",
    "\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                output, hidden, cell, _ = model.decoder(input, hidden, cell, encoder_outputs)\n",
    "                log_probs = F.log_softmax(output, dim=1)\n",
    "\n",
    "            top_log_probs, top_idx = log_probs.topk(beam_width)\n",
    "            for i in range(beam_width):\n",
    "                word_idx = top_idx[0][i].item()\n",
    "                log_prob = top_log_probs[0][i].item()\n",
    "\n",
    "                new_node = BeamSearchNode((hidden, cell), node, word_idx, node.logp + log_prob, node.length + 1)\n",
    "                new_nodes.append(new_node)\n",
    "\n",
    "        \n",
    "        nodes = sorted(new_nodes, key=lambda node: node.eval(), reverse=True)[:beam_width]\n",
    "\n",
    "    \n",
    "    end_node = nodes[0]\n",
    "    output_sequence = [end_node.wordid]\n",
    "\n",
    "    \n",
    "    while end_node.prevNode:\n",
    "        end_node = end_node.prevNode\n",
    "        output_sequence.append(end_node.wordid)\n",
    "\n",
    "    output_sequence = output_sequence[::-1]  # Reverse to get correct order\n",
    "\n",
    "    # Convert indices to tokens\n",
    "    output_tokens = []\n",
    "    for i in output_sequence:\n",
    "        if i == formula_vocab[\"<eos>\"]: \n",
    "            break\n",
    "        elif i == formula_vocab[\"<sos>\"]:\n",
    "            continue\n",
    "        else:\n",
    "            output_tokens.append(list(formula_vocab.keys())[list(formula_vocab.values()).index(i)])\n",
    "\n",
    "    return output_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "problem_text =\"in what time will a train 120 m long cross an electric pole , it its speed be 121 km / hr ?\"\n",
    "encoded_input = tokenizer.encode_plus(problem_text, return_tensors='pt', max_length=256, padding='max_length', truncation=True)\n",
    "input_ids = encoded_input['input_ids']\n",
    "attention_mask = encoded_input['attention_mask']\n",
    "\n",
    "# Beam search with BERT model\n",
    "output_tokens = beam_search(model, input_ids, attention_mask)\n",
    "\n",
    "str = ''\n",
    "for tok in output_tokens :\n",
    "    str += tok\n",
    "print(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf799f",
   "metadata": {
    "id": "RmT5sNf24jlg",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for entry in test_data:\n",
    "\n",
    "    problem_text = entry[\"Problem\"]  \n",
    "    # tokenized_problems = [text_to_indices(item[\"Problem\"], problem_vocab) for item in data]\n",
    "\n",
    "    encoded_input = tokenizer.encode_plus(problem_text, return_tensors='pt', max_length=256, padding='max_length', truncation=True)\n",
    "    input_ids = encoded_input['input_ids']\n",
    "    attention_mask = encoded_input['attention_mask']\n",
    "\n",
    "    # Beam search with BERT model\n",
    "    output_tokens = beam_search(model, input_ids, attention_mask, beam_width=1,max_len=80)\n",
    "\n",
    "    str=\"\"\n",
    "    for tok in output_tokens:\n",
    "      str+=tok\n",
    "    entry[\"predicted\"] = str\n",
    "\n",
    "    with open('/content/drive/MyDrive/DL_part_2/bert_finetuned_test_predictions_beam_1.json', 'w') as f_out:\n",
    "        json.dump(test_data, f_out, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b95aa2",
   "metadata": {
    "id": "PRrTdF_ZQY7C",
    "outputId": "907af9ad-fc46-45d5-c189-c5a652971123",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for entry in test_data:\n",
    "   \n",
    "    problem_text = entry[\"Problem\"]  \n",
    "\n",
    "    # tokenized_problems = [text_to_indices(item[\"Problem\"], problem_vocab) for item in data]\n",
    "\n",
    "    encoded_input = tokenizer.encode_plus(problem_text, return_tensors='pt', max_length=256, padding='max_length', truncation=True)\n",
    "    input_ids = encoded_input['input_ids']\n",
    "    attention_mask = encoded_input['attention_mask']\n",
    "\n",
    "    # Beam search with BERT model\n",
    "    output_tokens = beam_search(model, input_ids, attention_mask, beam_width=10,max_len=80)\n",
    "\n",
    "    str=\"\"\n",
    "    for tok in output_tokens:\n",
    "      str+=tok\n",
    "    entry[\"predicted\"] = str\n",
    "\n",
    "    with open('/content/drive/MyDrive/DL_part_2/bert_finetuned_test_predictions_beam_10.json', 'w') as f_out:\n",
    "        json.dump(test_data, f_out, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ade4c0",
   "metadata": {
    "id": "pTcR7I7HQdXh",
    "outputId": "87eca4b9-8d27-4a98-e505-694d6adbfe78",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for entry in test_data:\n",
    "    \n",
    "    problem_text = entry[\"Problem\"]  \n",
    "\n",
    "    # tokenized_problems = [text_to_indices(item[\"Problem\"], problem_vocab) for item in data]\n",
    "\n",
    "    encoded_input = tokenizer.encode_plus(problem_text, return_tensors='pt', max_length=256, padding='max_length', truncation=True)\n",
    "    input_ids = encoded_input['input_ids']\n",
    "    attention_mask = encoded_input['attention_mask']\n",
    "\n",
    "    # Beam search with BERT model\n",
    "    output_tokens = beam_search(model, input_ids, attention_mask, beam_width=20,max_len=100)\n",
    "\n",
    "    str=\"\"\n",
    "    for tok in output_tokens:\n",
    "      str+=tok\n",
    "    entry[\"predicted\"] = str\n",
    "\n",
    "    with open('/content/drive/MyDrive/DL_part_2/bert_finetuned_test_predictions_beam_20.json', 'w') as f_out:\n",
    "        json.dump(test_data, f_out, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75baed0a",
   "metadata": {
    "id": "Q-IiaeM1Qhut",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4710564,
     "sourceId": 7999546,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4710581,
     "sourceId": 7999571,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31524.177427,
   "end_time": "2024-04-02T01:03:27.493253",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-01T16:18:03.315826",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00b590c9d2aa4bb9ac8d93cde0b6b59e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2339a506380942fb94e39bf35da7e2fd",
       "placeholder": "​",
       "style": "IPY_MODEL_a633df0715db4af1b70c48936cceba9c",
       "value": "model.safetensors: 100%"
      }
     },
     "028616eafdf14139a8496d75d6560092": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "062f5c955eb84902ad4825ee0ea41feb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f33cd8eaa1245ac9aaeaf9e759a99a8",
       "placeholder": "​",
       "style": "IPY_MODEL_e33a24f1ac044a589bc8d2a047f0662d",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "0636798403444abda92f3b74b9c9272d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0799185a92984e2ebec65ffd2ca85bad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "085ded8ff5bd48c08cba90103d8ac88d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c2445afb75964d18a2f3f8b8d251ab9e",
       "placeholder": "​",
       "style": "IPY_MODEL_2fd4562e50814eda8faae28909f43c56",
       "value": "tokenizer.json: 100%"
      }
     },
     "0b263fec1edd4edfa41ee7eb931bf5d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_028616eafdf14139a8496d75d6560092",
       "max": 213450,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2a0f9875271484fb82749234b3c9387",
       "value": 213450
      }
     },
     "117bb1dadb4143e1ac2aa8e6c0b30b93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1a9693e5aca44a588d6ee51929f4b370",
       "placeholder": "​",
       "style": "IPY_MODEL_c92854d7156f449d9105eccb5aa49bc8",
       "value": "config.json: 100%"
      }
     },
     "127449f30b704ae0b5b8c84705af0524": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a9693e5aca44a588d6ee51929f4b370": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ade31641be4405c97ca149dbf14509e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00b590c9d2aa4bb9ac8d93cde0b6b59e",
        "IPY_MODEL_e28f88c497de4590a37a7a06366b2448",
        "IPY_MODEL_1f8638ec44ad4034ad374b004b143e82"
       ],
       "layout": "IPY_MODEL_d4a628cc520d443dba425ae8542fd55c"
      }
     },
     "1e9e1266fc7f49ea9987300b76683629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1f8638ec44ad4034ad374b004b143e82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_34d73d10659548a3af955242044396a5",
       "placeholder": "​",
       "style": "IPY_MODEL_0636798403444abda92f3b74b9c9272d",
       "value": " 436M/436M [00:01&lt;00:00, 289MB/s]"
      }
     },
     "2339a506380942fb94e39bf35da7e2fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "239cf4b17c2046a7b4d57667fa87ff3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_23c23febc248420bacffe06e9fff80f9",
       "max": 435797,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e9e1266fc7f49ea9987300b76683629",
       "value": 435797
      }
     },
     "23c23febc248420bacffe06e9fff80f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27cd1a52473b424c99be2abeffaf8636": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2fd4562e50814eda8faae28909f43c56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "34d73d10659548a3af955242044396a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4231b06b97af47c1b70dd9696bf22f70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "43bb08791a84412ca6636b530b5e14dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "499cb684d61f4a4ba2d00893518a5cc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_117bb1dadb4143e1ac2aa8e6c0b30b93",
        "IPY_MODEL_746614b898014fa898396dbf64282778",
        "IPY_MODEL_5de38123311a4063bd93b313d56b241b"
       ],
       "layout": "IPY_MODEL_51b5680cc7c6400cbe74bbc2306af0d3"
      }
     },
     "4c6ef8fbfe87463db1e0c971b59b1157": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51b5680cc7c6400cbe74bbc2306af0d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57ca535e26ba4b0a9f11765fb1363d3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7cd6ab1d290b47ae87ce1cd52d350840",
       "placeholder": "​",
       "style": "IPY_MODEL_7ba2c9dd462a4f00ba6e02083863442a",
       "value": " 213k/213k [00:00&lt;00:00, 6.08MB/s]"
      }
     },
     "5de38123311a4063bd93b313d56b241b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5177c7880a74941a8689a666ba311cd",
       "placeholder": "​",
       "style": "IPY_MODEL_83594c5fff9f4a5da7dcd6c83bbebe52",
       "value": " 570/570 [00:00&lt;00:00, 51.7kB/s]"
      }
     },
     "5f33cd8eaa1245ac9aaeaf9e759a99a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "652f50a36aca42988bd55fa726aa8002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "66b25c411f324a64a7813cc0499dc485": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_085ded8ff5bd48c08cba90103d8ac88d",
        "IPY_MODEL_239cf4b17c2046a7b4d57667fa87ff3f",
        "IPY_MODEL_cd94d1ba99a44825a9666ccc24d64a1c"
       ],
       "layout": "IPY_MODEL_910efd1fa17e4c4db44f76218de5aad6"
      }
     },
     "746614b898014fa898396dbf64282778": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_954fce5a4cb24109b5468e42281b22f4",
       "max": 570,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_652f50a36aca42988bd55fa726aa8002",
       "value": 570
      }
     },
     "7ad0cdbcaf69403185dee3d94d333315": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_127449f30b704ae0b5b8c84705af0524",
       "placeholder": "​",
       "style": "IPY_MODEL_7f6e85096c8b4cb08da592040768f278",
       "value": " 49.0/49.0 [00:00&lt;00:00, 4.03kB/s]"
      }
     },
     "7ba2c9dd462a4f00ba6e02083863442a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7cd6ab1d290b47ae87ce1cd52d350840": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d0ed9de7f24445b810765f781d58c21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d3cd7efb31fd47bc83f3980b6630b4c5",
        "IPY_MODEL_0b263fec1edd4edfa41ee7eb931bf5d9",
        "IPY_MODEL_57ca535e26ba4b0a9f11765fb1363d3f"
       ],
       "layout": "IPY_MODEL_81c27cbd96974804b0ce65afc218dc76"
      }
     },
     "7f6e85096c8b4cb08da592040768f278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "81c27cbd96974804b0ce65afc218dc76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83594c5fff9f4a5da7dcd6c83bbebe52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "878667a14517459184d8c1faed373f62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c6f0de586194b8198181d1b63ad6b23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "910efd1fa17e4c4db44f76218de5aad6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "954fce5a4cb24109b5468e42281b22f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2a0f9875271484fb82749234b3c9387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a633df0715db4af1b70c48936cceba9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c2445afb75964d18a2f3f8b8d251ab9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5177c7880a74941a8689a666ba311cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c92854d7156f449d9105eccb5aa49bc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cd94d1ba99a44825a9666ccc24d64a1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43bb08791a84412ca6636b530b5e14dd",
       "placeholder": "​",
       "style": "IPY_MODEL_dfefe9039291498fa0981ef98be48b4e",
       "value": " 436k/436k [00:00&lt;00:00, 3.30MB/s]"
      }
     },
     "d3cd7efb31fd47bc83f3980b6630b4c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_27cd1a52473b424c99be2abeffaf8636",
       "placeholder": "​",
       "style": "IPY_MODEL_0799185a92984e2ebec65ffd2ca85bad",
       "value": "vocab.txt: 100%"
      }
     },
     "d4a628cc520d443dba425ae8542fd55c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dbe2abd6cf0048b1a3203ba357a969fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8c6f0de586194b8198181d1b63ad6b23",
       "max": 49,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4231b06b97af47c1b70dd9696bf22f70",
       "value": 49
      }
     },
     "dfefe9039291498fa0981ef98be48b4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e28f88c497de4590a37a7a06366b2448": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_878667a14517459184d8c1faed373f62",
       "max": 435755784,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f9a105af24004d6288d5732c31827470",
       "value": 435755784
      }
     },
     "e33a24f1ac044a589bc8d2a047f0662d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e66f4d938edf4be4a640d86e205834a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_062f5c955eb84902ad4825ee0ea41feb",
        "IPY_MODEL_dbe2abd6cf0048b1a3203ba357a969fd",
        "IPY_MODEL_7ad0cdbcaf69403185dee3d94d333315"
       ],
       "layout": "IPY_MODEL_4c6ef8fbfe87463db1e0c971b59b1157"
      }
     },
     "f9a105af24004d6288d5732c31827470": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
